{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTk2oU2eQ3ih"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"anusha.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1gixfiGoBiTleTY6dxX6ZHXxWhPfO1A1Q\n",
        "\n",
        "**IMPORTING** **LIBRARIES**\n",
        "\"\"\"\n",
        "\n",
        "import nbformat\n",
        "nb = nbformat.read('anusha.ipynb', as_version=nbformat.NO_CONVERT)\n",
        "for cell in nb.cells:\n",
        "    cell.metadata.pop('widgets', None)\n",
        "nbformat.write(nb, 'anusha.ipynb')\n",
        "\n",
        "!pip install --upgrade datasets\n",
        "!pip install seqeval\n",
        "\n",
        "from datasets import load_dataset\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM,\\\n",
        " TimeDistributed, Dense, Dropout\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "import os\n",
        "from seqeval.metrics import classification_report, f1_score, precision_score,\\\n",
        " recall_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "\"\"\"To avoid potential errors when loading datasets in environments like Google Colab, we first delete the default Hugging Face cache directory. This helps prevent issues caused by outdated or incompatible cached files. Next, we set a custom cache path to a temporary directory (/tmp/huggingface_datasets), which ensures that any new datasets are downloaded and stored in a location that is more stable and compatible with Colab’s file system.\"\"\"\n",
        "\n",
        "# Remove the default Hugging Face dataset cache directory\n",
        "!rm -rf /root/.cache/huggingface/datasets\n",
        "# Set custom cache directory to /tmp\n",
        "import os\n",
        "os.environ[\"HF_DATASETS_CACHE\"] = \"/tmp/huggingface_datasets\"\n",
        "\n",
        "\"\"\"In this step, we load the CoNLL-2003 dataset using the load_dataset function from the Hugging Face datasets library. This dataset is a popular benchmark for named entity recognition tasks and includes labeled text for training, validation, and testing. Since the dataset includes custom loading logic, we pass trust_remote_code=True to allow Hugging Face to run that logic safely — a necessary step for proper parsing. After loading, we print the dataset object to verify that it was successfully downloaded and to inspect the available data splits and structure.\"\"\"\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"conll2003\", trust_remote_code=True)\n",
        "\n",
        "print(dataset)\n",
        "\n",
        "\"\"\"Before jumping into preprocessing, it's important to explore and understand the dataset. In this step, we inspect the structure of the CoNLL-2003 dataset by printing out its available splits — typically train, validation, and test. We then look closer at the training split to understand its size, the type of data it holds, and the names of the columns. This includes features like 'tokens', which represent the words in a sentence, and 'ner_tags', which contain the corresponding named entity labels. Finally, we preview a few sample rows to get a feel for how the data is organized. These checks are essential for designing the right preprocessing steps and avoiding errors later on.\"\"\"\n",
        "\n",
        "# Inspect the dataset\n",
        "# A DatasetDict object has keys corresponding to the dataset splits\n",
        "print(\"Dataset splits available:\", dataset.keys())\n",
        "\n",
        "# trainsplit information:\n",
        "print(\"\\nInformation about the train split:\")\n",
        "print(dataset['train'])\n",
        "\n",
        "# column names and types of the train split:\n",
        "print(\"\\nFeatures columns of the train split:\")\n",
        "print(dataset['train'].features)\n",
        "\n",
        "# sample rows\n",
        "print(\"\\nFirst 5 examples from the train split:\")\n",
        "print(dataset['train'].select(range(5)))\n",
        "\n",
        "\"\"\"At this stage, we extract the actual content we'll use to train and evaluate our model. From the CoNLL-2003 dataset, we retrieve the tokens word-level sentence inputs and the ner_tags corresponding label sequences for both the training and validation sets. Each sentence is represented as a list of words, and each tag sequence is a list of integer labels that identify entity types for each word. By printing out the first sentence and tag pair from each split, we can quickly confirm that the data has been loaded correctly and that the tokens and labels are aligned. This forms the foundation for the preprocessing and model training steps that follow.\"\"\"\n",
        "\n",
        "# Extract sentence tokens and corresponding NER tag sequences from training set\n",
        "\n",
        "train_sentences = dataset[\"train\"][\"tokens\"]\n",
        "train_tags = dataset[\"train\"][\"ner_tags\"]\n",
        "\n",
        "val_sentences = dataset[\"validation\"][\"tokens\"]\n",
        "val_tags = dataset[\"validation\"][\"ner_tags\"]\n",
        "\n",
        "# Print the first training sentence and its tags\n",
        "# This helps verify that the data is correctly extracted and aligned\n",
        "print(train_sentences[0])\n",
        "print(train_tags[0])\n",
        "\n",
        "print(val_sentences[0])\n",
        "print(val_tags[0])\n",
        "\n",
        "# List of label names\n",
        "label_list = dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
        "num_labels = len(label_list)\n",
        "\n",
        "print(label_list)\n",
        "print(num_labels)\n",
        "\n",
        "\"\"\"Before we can feed data into our model, we need to translate both words and labels into numerical form. To do this, we build two sets of dictionaries. The first is word2idx, which maps every unique word in the training set to a unique integer ID. We also reserve special IDs: 0 for \"PAD\" tokens (used for sequence padding), and 1 for \"UNK\" (used for unknown or out-of-vocabulary words). This ensures our model can handle any text input consistently. Alongside this, we create idx2word, which reverses this mapping — helpful for decoding predictions later.\n",
        "\n",
        "Next, we construct label mappings: label2idx maps each NER tag (like \"B-PER\" or \"O\") to an integer, while idx2label does the reverse. These mappings allow the model to treat tag classification as a multi-class problem and convert its numeric outputs back into meaningful tag names.\n",
        "\"\"\"\n",
        "\n",
        "#Create vocabulary and label dictionaries\n",
        "\n",
        "# Build word2idx from training set\n",
        "word_set = set(word for sentence in train_sentences for word in sentence)\n",
        "word2idx = {word: idx + 2 for idx, word in enumerate(sorted(word_set))}\n",
        "word2idx[\"PAD\"] = 0\n",
        "word2idx[\"UNK\"] = 1\n",
        "\n",
        "# Reverse\n",
        "idx2word = {i: w for w, i in word2idx.items()}\n",
        "\n",
        "# Labels\n",
        "label2idx = {label: idx for idx, label in enumerate(label_list)}\n",
        "idx2label = {idx: label for label, idx in label2idx.items()}\n",
        "\n",
        "# Set the maximum sequence length for padding\n",
        "MAX_LEN = 50\n",
        "\n",
        "# Function to convert each sentence into a list of word indices\n",
        "# Uses 'UNK' index for any word not in the vocabulary\n",
        "# Pads each sentence to the same length using 'PAD' token\n",
        "def encode_sentences(sentences, word2idx, max_len):\n",
        "    encoded = [[word2idx.get(word, word2idx[\"UNK\"]) for word in s] for s in sentences]\n",
        "    return pad_sequences(encoded, maxlen=max_len, padding=\"post\", value=word2idx[\"PAD\"])\n",
        "\n",
        "# Function to pad the label sequences so they match the input length\n",
        "# Uses the index for 'O' (non-entity) to pad labels\n",
        "def encode_labels(tags, max_len):\n",
        "    padded = pad_sequences(tags, maxlen=max_len,\n",
        "                           padding=\"post\", value=label2idx[\"O\"])\n",
        "    return np.array(padded)\n",
        "\n",
        "# Apply encoding to training and validation input sequences\n",
        "X_train = encode_sentences(train_sentences, word2idx, MAX_LEN)\n",
        "X_val = encode_sentences(val_sentences, word2idx, MAX_LEN)\n",
        "\n",
        "# Apply encoding to the corresponding NER tag sequences\n",
        "y_train = encode_labels(train_tags, MAX_LEN)\n",
        "y_val = encode_labels(val_tags, MAX_LEN)\n",
        "\n",
        "#One-hot encode the output labels\n",
        "y_train = to_categorical(y_train, num_classes=num_labels)\n",
        "y_val = to_categorical(y_val, num_classes=num_labels)\n",
        "\n",
        "# Model hyperparameters\n",
        "VOCAB_SIZE = len(word2idx)      # total unique words\n",
        "EMBEDDING_DIM = 64              # size of each word vector\n",
        "LSTM_UNITS = 64                 # number of hidden units in LSTM\n",
        "MAX_LEN = 50                    # sequence length (already defined)\n",
        "NUM_CLASSES = num_labels        # number of unique NER tags\n",
        "\n",
        "# Input layer: takes in a sequence of word indices\n",
        "input = Input(shape=(MAX_LEN,))\n",
        "\n",
        "# Embedding layer\n",
        "# Turns word indices into dense vectors (learned during training)\n",
        "model = Embedding(input_dim=VOCAB_SIZE,\n",
        "                  output_dim=EMBEDDING_DIM,\n",
        "                  input_length=MAX_LEN\n",
        "                  )(input)\n",
        "\n",
        "# Bidirectional LSTM\n",
        "# Processes input in both directions forward & backward for better context\n",
        "model = Bidirectional(LSTM(units=LSTM_UNITS, return_sequences=True))(model)\n",
        "\n",
        "#Dropout layer helps prevent overfitting\n",
        "model = Dropout(0.3)(model)\n",
        "\n",
        "# TimeDistributed Dense layer\n",
        "# Applies a Dense layer to each time step individually\n",
        "model = TimeDistributed(Dense(NUM_CLASSES, activation=\"softmax\"))(model)\n",
        "\n",
        "# Build and compile model\n",
        "model = Model(inputs=input, outputs=model)\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# Categorical crossentropy because labels are one-hot encoded\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Number of training epochs\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Fit the model on the training data and validate on validation set\n",
        "bi_lstm = model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(X_val, y_val),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Plot training vs validation accuracy\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(bi_lstm.bi_lstm['accuracy'], label='Train Acc')\n",
        "plt.plot(bi_lstm.bi_lstm['val_accuracy'], label='Val Acc')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(bi_lstm.bi_lstm['loss'], label='Train Loss')\n",
        "plt.plot(bi_lstm.bi_lstm['val_loss'], label='Val Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "model.save(\"bilstm_ner_model.h5\")\n",
        "\n",
        "# predictions\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# For each token getting highest probability\n",
        "y_pred_labels = np.argmax(y_pred, axis=-1)\n",
        "y_true_labels = np.argmax(y_val, axis=-1)\n",
        "\n",
        "# Using the idx2label map to convert indices to strings\n",
        "def decode_tags(label_indices):\n",
        "    return [[idx2label[idx] for idx in sentence] for sentence in label_indices]\n",
        "\n",
        "predicted_tags = decode_tags(y_pred_labels)\n",
        "true_tags = decode_tags(y_true_labels)\n",
        "\n",
        "def show_predictions(n=3):\n",
        "    for i in range(n):\n",
        "        print(f\"\\nSentence {i+1}:\")\n",
        "        print(\"Tokens     :\", val_sentences[i])\n",
        "        print(\"True Tags  :\", true_tags[i])\n",
        "        print(\"Predicted  :\", predicted_tags[i])\n",
        "\n",
        "# first 3 samples\n",
        "show_predictions(3)\n",
        "\n",
        "# Evaluate only up to the original sentence lengths (remove padded values)\n",
        "def remove_pads(preds, labels, masks):\n",
        "    clean_preds, clean_labels = [], []\n",
        "    for pred_seq, label_seq, mask_seq in zip(preds, labels, masks):\n",
        "        filtered_pred = []\n",
        "        filtered_label = []\n",
        "        for p, l, m in zip(pred_seq, label_seq, mask_seq):\n",
        "            if m != 0:  # 0 = padding\n",
        "                filtered_pred.append(p)\n",
        "                filtered_label.append(l)\n",
        "        clean_preds.append(filtered_pred)\n",
        "        clean_labels.append(filtered_label)\n",
        "    return clean_preds, clean_labels\n",
        "\n",
        "# Create a mask (1 = real token, 0 = padding)\n",
        "mask_val = (X_val != word2idx['PAD']).astype(int)\n",
        "\n",
        "# Clean predictions and labels\n",
        "preds_clean, labels_clean = remove_pads(predicted_tags, true_tags, mask_val)\n",
        "\n",
        "# Calculate F1, precision, recall\n",
        "print(\" Evaluation Metrics:\")\n",
        "print(\"F1 Score      :\", f1_score(labels_clean, preds_clean))\n",
        "print(\"Precision     :\", precision_score(labels_clean, preds_clean))\n",
        "print(\"Recall        :\", recall_score(labels_clean, preds_clean))\n",
        "\n",
        "# Detailed per-class report\n",
        "print(\"\\n Classification Report:\")\n",
        "print(classification_report(labels_clean, preds_clean))\n",
        "\n",
        "# Flatten predictions and true labels\n",
        "flat_true = [label for seq in true_tags for label in seq if label != 'O']\n",
        "flat_pred = [pred for seq, true_seq in zip(predicted_tags, true_tags)\n",
        "             for pred, true in zip(seq, true_seq) if true != 'O']\n",
        "\n",
        "# Confusion matrix\n",
        "classes = ['LOC', 'MISC', 'ORG', 'PER']\n",
        "\n",
        "# removes B- and I- prefixes\n",
        "cm = confusion_matrix(\n",
        "    [tag.replace('B-', '').replace('I-', '') for tag in flat_true],\n",
        "    [tag.replace('B-', '').replace('I-', '') for tag in flat_pred],\n",
        "    labels=classes\n",
        ")\n",
        "\n",
        "# Plot\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix for Named Entity Classes\")\n",
        "plt.show()\n"
      ]
    }
  ]
}